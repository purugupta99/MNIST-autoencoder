# -*- coding: utf-8 -*-
"""q3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Dy-PbjaUZpq5-D-fZch0jJi8mSjmvzAm

## Simple Model -- Undercomplete AE
"""

# Code here
import torch
import torch.nn as nn
import torchvision
import torchvision.datasets as datasets
import torchvision.transforms as transforms
import torch.nn.init as weight_init
import matplotlib.pyplot as plt
import pdb
from torch.utils.data.sampler import SubsetRandomSampler
from sklearn.metrics import mean_squared_error
from sklearn.svm import SVC


#parameters
batch_size = 128

preprocess = transforms.Compose([
                           transforms.ToTensor(),
                           transforms.Normalize((0.1307,), (0.3081,))
                       ])

#Loading the train set file
dataset = datasets.MNIST(root='./data',
                            transform=preprocess,  
                            download=True)

loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)

"""### Autoencoder Class"""

class AE(nn.Module):
    def __init__(self, encode_sz):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Linear(28*28, 256),
            nn.ReLU(),
            nn.Linear(256,64),
            nn.ReLU(),
            nn.Linear(64,encode_sz),
        )
        self.decoder = nn.Sequential(
            nn.Linear(encode_sz, 64),
            nn.ReLU(),
            nn.Linear(64, 256),
            nn.ReLU(),
            nn.Linear(256, 28*28),
            nn.Tanh()
        )
    
    def forward(self,x):
        h = self.encoder(x)
        xr = self.decoder(h)
        return xr,h

#Misc functions
def loss_plot(losses):
    max_epochs = len(losses)
    times = list(range(1, max_epochs+1))
    plt.figure(figsize=(30, 7))
    plt.xlabel("epochs")
    plt.ylabel("cross-entropy loss")
    return plt.plot(times, losses)

use_cuda = torch.cuda.is_available()
device = torch.device("cuda" if use_cuda else "cpu")
print('Using CUDA ', use_cuda)


#Optimizer and Scheduler
# optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=weight_decay)
# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, threshold=0.001, patience=5, verbose = True)

# Commented out IPython magic to ensure Python compatibility.
num_epochs = 10
features = 50

net = AE(features)
net = net.to(device)

#Mean square loss function
criterion = nn.MSELoss()

#Parameters
learning_rate = 1e-2
weight_decay = 1e-5


optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=weight_decay)
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, threshold=0.001, patience=5, verbose = True)

epochLoss = []
for epoch in range(num_epochs):
    total_loss, cntr = 0, 0
    
    for i,(images,_) in enumerate(loader):
        
        images = images.view(-1, 28*28)
        images = images.to(device)
        
        # Initialize gradients to 0
        optimizer.zero_grad()
        
        # Forward pass (this calls the "forward" function within Net)
        outputs, _ = net(images)
        
        # Find the loss
        loss = criterion(outputs, images)
        
        # Find the gradients of all weights using the loss
        loss.backward()
        
        # Update the weights using the optimizer and scheduler
        optimizer.step()
      
        total_loss += loss.item()
        cntr += 1
    
    scheduler.step(total_loss/cntr)
    print ('Epoch [%d/%d], Loss: %.4f' 
#                   %(epoch+1, num_epochs, total_loss/cntr))
    epochLoss.append(total_loss/cntr)

#Feature Extraction
ndata = len(dataset)
hSize = 50

test_dataset = datasets.MNIST(root='./data',
                            transform=preprocess,  
                            download=True)
test_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)

iMat = torch.zeros((ndata,28*28))
rMat = torch.zeros((ndata,28*28))
featMat = torch.zeros((ndata,hSize))
labelMat = torch.zeros((ndata))
cntr=0

with torch.no_grad():
    for i,(images,labels) in enumerate(loader):

        images = images.view(-1, 28*28)
        images = images.to(device)
        
        rImg, hFeats = net(images)
        
        iMat[cntr:cntr+batch_size,:] = images
        rMat[cntr:cntr+batch_size,:] = (rImg+0.1307)*0.3081
        
        featMat[cntr:cntr+batch_size,:] = hFeats
        labelMat[cntr:cntr+batch_size] = labels
        
        cntr+=batch_size
        
        if cntr>=ndata:
            break

print(featMat[6,:].shape)
print(enumerate(loader))
print(labelMat)
plt.figure()
plt.axis('off')
plt.imshow(rMat[6,:].view(28,28),cmap='gray')

featMat = featMat[:10000]
labelMat = labelMat[:10000]

num_train = len(labelMat)
splitIndex = int(num_train * 0.7)

X_train = featMat[:splitIndex] 
y_train = labelMat[:splitIndex]

X_test = featMat[splitIndex:] 
y_test = labelMat[splitIndex:]

print(X_train.shape)

model_encode = SVC(C=.1,kernel='rbf')
model_encode.fit(X_train, y_train)

prediction_encode = model_encode.predict(X_test)

acc = 0
for i in range(len(y_test)):
    if prediction_encode[i] == y_test[i]:
        acc += 1
accuracy_encode = acc/len(y_test) * 100

print(accuracy_encode)

from sklearn.decomposition import PCA

iNPMat = iMat[:10000].numpy()

pca = PCA(n_components=50)
pca.fit(iNPMat)

#Projection
pcaProj = (iNPMat - pca.mean_).dot(pca.components_.T)
print(pcaProj.shape)

X_train = iMat[:splitIndex] 
y_train = labelMat[:splitIndex]

X_test = iMat[splitIndex:] 
y_test = labelMat[splitIndex:]

model_pca = SVC(C=.1,kernel='rbf')
model_pca.fit(X_train, y_train)
prediction = model_pca.predict(X_test)

acc = 0
for i in range(len(y_test)):
    if prediction[i] == y_test[i]:
        acc += 1
accuracy_pca = acc/len(y_test) * 100

print(accuracy_pca)

import numpy as np
import matplotlib.pyplot as plt

objects = ('Extracted Features', 'Raw pixels')
y_pos = np.arange(len(objects))
performance = [accuracy_encode, accuracy_pca]

fig = plt.figure()
plt.figure(figsize=(15,7.5))

plt.bar(y_pos, performance, align='center', alpha=0.5)
plt.xticks(y_pos, objects)
plt.ylabel('Accuracy')
plt.title('Accuracy vs. Classifier')

plt.show()